import argparse

def get_argument_parser():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_path', default='your dataset path', help='path to datasets')
    parser.add_argument('--data_name', default='f30k', help='{coco,f30k}_precomp')
    parser.add_argument('--vocab_path', default='./vocab/', help='Path to saved vocabulary json files.')
    parser.add_argument('--margin', default=0.2, type=float, help='Rank loss margin.')
    parser.add_argument('--num_epochs', default=30, type=int, help='Number of training epochs.')
    parser.add_argument('--batch_size', default=128, type=int, help='Size of a training mini-batch.')
    parser.add_argument('--word_dim', default=300, type=int, help='Dimensionality of the word embedding.')
    parser.add_argument('--embed_size', default=1024, type=int, help='Dimensionality of the joint embedding.')
    parser.add_argument('--grad_clip', default=2., type=float, help='Gradient clipping threshold.')
    parser.add_argument('--learning_rate', default=.0005, type=float, help='Initial learning rate.')
    parser.add_argument('--lr_update', default=10, type=int, help='Number of epochs to update the learning rate.')
    parser.add_argument('--optim', default='adam', type=str, help='the optimizer')
    parser.add_argument('--workers', default=0, type=int, help='Number of data loader workers.')
    parser.add_argument('--log_step', default=200, type=int, help='Number of steps to logger.info and record the log.')
    parser.add_argument('--val_step', default=100, type=int, help='Number of steps to run validation.')
    parser.add_argument('--logger_name', default='./runs/', help='Path to save Tensorboard log.')
    parser.add_argument('--model_name', default='./runs/', help='Path to save the model.')
    parser.add_argument('--resume', default='', type=str, metavar='PATH', help='path to latest checkpoint (default: none)')
    parser.add_argument('--max_violation', action='store_true', help='Use max instead of sum in the rank loss.')
    parser.add_argument('--img_dim', default=2048, type=int, help='Dimensionality of the image embedding.')
    parser.add_argument('--no_imgnorm', action='store_true', help='Do not normalize the image embeddings.')
    parser.add_argument('--no_txtnorm', action='store_true', help='Do not normalize the text embeddings.')
    parser.add_argument('--precomp_enc_type', default="basic", help='basic|backbone')
    parser.add_argument('--backbone_path', type=str, default='./data/weights/original_updown_backbone.pth', help='path to the pre-trained backbone net')
    parser.add_argument('--backbone_source', type=str, default='detector', help='the source of the backbone model, detector|imagenet')
    parser.add_argument('--vse_mean_warmup_epochs', type=int, default=1, help='The number of warmup epochs using mean vse loss')
    parser.add_argument('--reset_start_epoch', action='store_true', help='Whether restart the start epoch when load weights')
    parser.add_argument('--backbone_warmup_epochs', type=int, default=0, help='The number of epochs for warmup')
    parser.add_argument('--embedding_warmup_epochs', type=int, default=1, help='The number of epochs for warming up the embedding layers')
    parser.add_argument('--backbone_lr_factor', default=0.01, type=float, help='The lr factor for fine-tuning the backbone, it will be multiplied to the lr of the embedding layers')
    parser.add_argument('--input_scale_factor', type=float, default=2.0, help='The factor for scaling the input image')
    parser.add_argument('--attention_lamda', default=1, type=int)
    parser.add_argument('--seed', default=1, type=int)
    parser.add_argument('--use_moco', default=1, type=int)
    parser.add_argument('--moco_M', default=2048, type=int)
    parser.add_argument('--moco_r', default=0.999, type=float)
    parser.add_argument('--loss_lamda', default=20, type=float)
    parser.add_argument('--mu', default=90, type=float)
    parser.add_argument('--gama', default=0.5, type=float)
                      
    return parser
